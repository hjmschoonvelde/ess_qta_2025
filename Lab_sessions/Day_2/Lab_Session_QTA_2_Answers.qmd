---
title: "QTA Lab Session 2: String operations and inspecting a corpus"
format: 
  #html: default
  gfm: default
editor: source

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, results = TRUE)
```

## String operations 

`R` stores text as a `string` or `character` vector. It is important to become comfortable with string operations, since they allow you to clean a string before you start analyzing your text. 

These string operations require familiarity with regular expressions in `R` as well as with functions in the **stringr** library.^[`R` is open source with different developers working on similar issues, as a result of which there can be multiple packages that do the same thing. For example, functions in base `R` and the **stringi** package also let you manipulate strings in `R`. However, the syntax of the function calls in these different packages is different.] 

Packages such as **quanteda** include some string cleaning functions as well but knowledge of regular expressions and string operations allow you to deal much better with with the specifics of your text. That said, these operations usually involve lots of trial and error, Google, or conversations with ChatGPT to figure out how to do certain things. But they help you clean your data, which will save you lot of headaches later on. Let's have a look at a set of useful functions.

First load the `stringr` library in `R`.

```{r}
#| label: "load_stringr_library"
#| echo: true
#| message: false
#| warning: false

library(stringr)

```

Then create a string vector called shopping_list:

```{r}
#| label: "shopping_list"
#| echo: true
#| message: false
#| warning: false

shopping_list <- c("4 bananas", " 136 2 Apples", "20 oranges", "1 Milk", "2 eggs")

```

Vectors are basic objects in `R` which contain a set of values of the same type (character, numeric, factor, etc.) The shopping_list contains five character. Check that this is true with the `str()` function: 

```{r}
#| label: "str"
#| echo: true
#| message: false
#| warning: false

str(shopping_list)

```

The `stringr` library contains many useful functions for working with character values, which are listed in this [cheat sheet](https://github.com/rstudio/cheatsheets/blob/master/strings.pdf). Let's go through a few examples, starting with the `str_extract()` function for basic pattern matching.

`str_extract()` takes in two arguments: a string and a pattern to look for. For each string it returns the pattern it found. Let's see if it finds a n in each of the strings:

```{r}
#| label: "str_extract"
#| echo: true
#| message: false
#| warning: false

str_extract(shopping_list, "n")

```
We can use `str_which()` to find the indexes of strings that contain a pattern match:

```{r}
#| label: "str_which"
#| echo: true
#| message: false
#| warning: false

str_which(shopping_list, "n")

```

Using `str_locate()` we can find the position of the first match in each string:

```{r}
#| label: "str_locate"
#| echo: true
#| message: false
#| warning: false

str_locate(shopping_list, "n")

```

Using `str_locate_all()` we can find the position of all matches in each string:

```{r}
#| label: "str_locate_all"
#| echo: true
#| message: false
#| warning: false

str_locate_all(shopping_list, "n")

```


Functions in the `stringr` library can work with regular expressions to extract content from a string vector in a more systematic way. For example, run the following line of code:

```{r}
#| label: "str_extract_regex"
#| echo: true
#| message: false
#| warning: false

str_extract(shopping_list, "\\d")

```

Here `d` is a regular expression which refers to any number (**NB**: without the escape character `\\` it would just refer to the letter d). See what happens when you replace `d` with `d+` like so: `str_extract(shopping_list, "\\d+")`. What does the + do?

```{r}
#| label: "str_extract_all_regex"
#| echo: true
#| message: false
#| warning: false

str_extract_all(shopping_list, "\\d+")
#your answer here

```

Let's turn to alphabetic characters (aka letters). The regular expression `[a-z]` refers to any lower case letter. The `+` symbol after `[a-z]` refers to one or more lower case letters. The `{3,4}` refers to a range of 3 to 4 lower case letters. The regular expression `[A-z]` refers to any upper or lower case letter. The `\\b` refers to a word boundary. Let's see how these work in practice:


```{r}
#| label: "str_extract_examples"
#| echo: true
#| message: false
#| warning: false

#extract the first lower case charachter in each string
str_extract(shopping_list, "[a-z]")

#extract lower case characters one or more times (again note the "+" symbol after "[a-z]")
str_extract(shopping_list, "[a-z]+")

#extract up to four lower case letters occurring in a row
str_extract(shopping_list, "[a-z]{3,4}")

#extract up to four upper OR lower case letters
str_extract(shopping_list, "[A-z]{1,4}")

#extract all letters in each string
str_extract_all(shopping_list, "[A-z]+")

#extract all numbers in each string
str_extract_all(shopping_list, "\\d+")

```

Note that str_extract_all generates a list of character strings as output. A list is a data structure in R that can hold different types of elements, including vectors, matrices, and other lists. Each element in the list corresponds to an element in the original vector, and each element in the list is itself a character vector containing the matches found by `str_extract_all()`. This can be simplified into a character matrix using the simplify command:

```{r}
#| label: "str_extract_all_simplify"
#| echo: true
#| message: false
#| warning: false

str_extract_all(shopping_list, "\\b[A-z]+\\b", 
                simplify = TRUE)

str_extract_all(shopping_list, "\\d", 
                simplify = TRUE)

```

Let's have a look at the `str_replace()` function, which replaces a pattern in a string with another pattern. This function takes in three arguments: _string, pattern and replacement_. The string is the text you want to modify, the pattern is the text you want to replace, and the replacement is the text you want to replace it with.

Let's replace the first vowel in each string with a dash. And then replace all vowels with a dash:

```{r}
#| label: "str_replace_examples"
#| echo: true
#| message: false
#| warning: false

#replace first vowel
str_replace(shopping_list, "[aeiou]", "-")

#replace all vowels
str_replace_all(shopping_list, "[aeiou]", "-")

```

In *R*, you write regular expressions as strings, sequences of characters surrounded by quotes ("") or single quotes (''). Characters like +, ?, ^, and . have a special meaning as regular expressions and cannot be represented directly in an R string (see the RegEx [cheat sheet](https://github.com/rstudio/cheatsheets/blob/master/strings.pdf) for more examples). In order to match them literally, they need to be preceded by two backslashes: ``\\".

Let's start with an example of a vector of names that for some reason contain dots and plus signs.


```{r}
#| label: "name_list"
#| echo: true
#| message: false
#| warning: false

name_list <- c("Jo.hn", "Anna.", "Si.+si", "Ma.ria")

```

Compare the output of these two calls

```{r}
#| label: "examples"
#| echo: true
#| message: false
#| warning: false

str_replace(name_list, ".", "-")
str_replace(name_list, "\\.", "-")

```

Ccompare the output of these two calls:

```{r}
#| label: "examples_2"
#| echo: true
#| message: false
#| warning: false

str_replace(name_list, ".+", "-")
str_replace(name_list, "\\.\\+", "-")
```

## Inspecting a corpus

For the next part of this script we'll first need to load the **quanteda** package. **quanteda** is a package for the quantitative analysis of textual data. It is a powerful package that allows you to preprocess, analyze, and visualize text data.

```{r}
#| label: "load_quanteda_library"
#| echo: true
#| message: false
#| warning: false

library(quanteda)

```

**quanteda** has several in-built corpora we can use for exercises. One of these corpora is `data_corpus_inaugural` which contains the inaugural speeches of all the American presidents in a corpus format. Type `summary(data_corpus_inaugural)` and inspect the object. 

```{r}
#| label: "summary_data_corpus_inaugural"
#| echo: true
#| message: false
#| warning: false

summary(data_corpus_inaugural,  n = 10)

```

Let's make a copy of this corpus. We'll save it in our working environment as an object called `speeches_inaugural`

```{r}
#| label: "create_speeches_inaugural"
#| echo: true
#| message: false
#| warning: false

speeches_inaugural <- data_corpus_inaugural

```

We can inspect the content of the first inaugural speech using `as.character()` function:


```{r}
#| label: "as.character_speeches_inaugural"
#| echo: true
#| message: false
#| warning: false

as.character(speeches_inaugural)[1]

```

This produces the text of George Washington's first inaugural speech. Metadata such as year, speaker, etc. are stored in a corpus object as _docvars_, and can be accessed like so: 

```{r}
#| label: "meta_data_speeches_inaugural"
#| echo: true
#| message: false
#| warning: false

#year
docvars(speeches_inaugural, "Year")

#party
head(docvars(speeches_inaugural, "Party"), 10)

```

Using the `table()` function we can inspect the number of presidents of each party:

```{r}
#| label: "table"
#| echo: true
#| message: false
#| warning: false

#number of presidents of each party
table(docvars(speeches_inaugural, "Party"))

```

We can also inspect the number of documents in the corpus using the `ndoc()` function:

```{r}
#| label: "ndoc"
#| echo: true
#| message: false
#| warning: false

ndoc(speeches_inaugural)

```

Subsetting a corpus is easy using the `corpus_subset()` function. Note the `==` operator here. In `R` `=` is primarily used for assignment within function calls. It assigns values to variables. It can also be used for variable assignment, but this usage is less common compared to the `<-` operator, which is the preferred assignment operator in R.
The `==` operator in `R` is used for comparison. It checks if two values are equal and returns a logical value (TRUE or FALSE).

Using the `==` operator, we can create an object that only contains the inaugural speech of Donald Trump and call it `trump_inaugural`

```{r}
#| label: "corpus_subset_trump_inaugural"
#| echo: true
#| message: false
#| warning: false

trump_inaugural <- corpus_subset(speeches_inaugural, President == "Trump")

ndoc(trump_inaugural)

```

As you can see, Trump appears twice in the corpus, once for his first inaugural speech in 2017 and once for his second inaugural speech in 2025. We can inspect the content of this corpus using `as.character()`:

```{r}
#| label: "display_trump_inaugural"
#| echo: true
#| message: false
#| warning: false


as.character(trump_inaugural)[1]
as.character(trump_inaugural)[2]


```

If the documents are clean enough (i.e., with correct interpunction etc.), then it is easy in **quanteda** to break down a document on a sentence to sentence basis using `corpus_reshape()`, which reshapes the corpus to a different level of granularity, in this case to the level of sentences.

```{r}
#| label: "sentneces_trump_inaugural"
#| echo: true
#| message: false
#| warning: false


trump_sentence <- corpus_reshape(trump_inaugural, to =  "sentences")

ndoc(trump_sentence)

```

As you can see, Trump's two inaugural speeches consisted of 304 sentences.

Before we preprocess our texts, we first need to tokenize it using `tokens()`. Tokenization is the process of breaking a text into smaller units, such as words. 

```{r}
#| label: "tokens_speeches_inaugural"
#| echo: true
#| message: false
#| warning: false


tokens_speeches_inaugural <- tokens(speeches_inaugural)

```

Using `tokens_compound()` we can create multiword expressions. Multiword expressions are phrases that consist of more than one word. Let's say we want to make certain that references to the `United States of America` are recognized as such in subsequent analyses. We can do so using the following line of code: 

```{r}
#| label: "tokens_compound"
#| echo: true
#| message: false
#| warning: false


tokens_speeches_inaugural <- tokens_compound(tokens_speeches_inaugural, phrase("United States of America"))

```

Let's see how often each President referred to the United States of America in their inaugural speeches:


```{r}
#| label: "usofa_count"
#| echo: true
#| message: false
#| warning: false


str_count(as.character(speeches_inaugural), "United States of America")

```
Apparently, this is a turn of phrase that is used more often in recent years, but not so much in the past.

Using the `kwic()` function, we can inspect the context in which the United States of America is used in these speeches. The `kwic()` function takes in a tokenized text and a pattern to look for. It returns a keyword-in-context (KWIC) object, which is a data frame that shows the context in which the pattern occurs. In this case we'll look at the context in which the United States of America of 10 words before and after the phrase:

```{r}
#| label: "kwic_usofa"
#| echo: true
#| message: false
#| warning: false


kwic(tokens_speeches_inaugural, 
     pattern = phrase("United_States_of_America"),
     window = 10)  %>%
  tail()

```


## Excercise: inspecting a corpus

For these exercises we'll use the `speeches_inaugural` corpus that we just created.

Explore `corpus_subset()` and filter only speeches delivered since 1990. Store this object as `speeches_inaug_since1990`. 

```{r}
#| label: "corpus_subset_exercise"
#| echo: true
#| message: false
#| warning: false

speeches_inaug_since1990 <- corpus_subset(speeches_inaugural, Year >= "1990")
ndoc(speeches_inaug_since1990)

```

Explore `corpus_reshape()`. Reshape `speeches_original_since1990`to the level of sentences and store this object as `sentences_inaug_since1990`. What is the number of sentences (= number of documents) in this text corpus?

```{r}
#| label: "corpus_reshape_exercise"
#| echo: true
#| message: false
#| warning: false


sentences_inaug_since1990 <- corpus_reshape(speeches_inaug_since1990, to =  "sentences")

ndoc(sentences_inaug_since1990)

```


Inspect how often references to the pursuit of happiness occur in this corpus:

```{r}
#| label: "pursuit_of_happiness"
#| echo: true
#| message: false
#| warning: false

str_count(as.character(sentences_inaug_since1990), "pursuit of happiness")


sum(str_count(as.character(sentences_inaug_since1990), "pursuit of happiness"))


docvars(sentences_inaug_since1990, "pursuit") <- str_count(as.character(sentences_inaug_since1990), "pursuit of happiness")


table(docvars(sentences_inaug_since1990, "pursuit"))

```

Tokenize the sentence-level text corpus. Make sure that references to the `Supreme Court`, `United States of America` and `pursuit of happiness` are included as multiword expressions.  

```{r}
#| label: "mwe_example"
#| echo: true
#| message: false
#| warning: false

tokens_inaug_since1990 <- tokens(sentences_inaug_since1990) %>%
  tokens_compound(phrase(c("Supreme Court", "pursuit of happiness", "United States of America")))


```


Use corpus_reshape() and change the unit of `speeches_inaug_since1990` to the level of paragraphs. How many paragraphs does this corpus contain?

```{r}
#| label: "corpus_reshape_paragraphs_exercise"
#| echo: true
#| message: false
#| warning: false

paragraphs_inaug_since1990 <- corpus_reshape(speeches_inaug_since1990, to =  "paragraphs")

ndoc(paragraphs_inaug_since1990)

```

## Excercise: cleaning a text vector

The local zoo has made an inventory of its animal stock.^[This exercise is based on an example from Automated Data Collection With R, by Munzert *et al* (2015).]  However, the zoo keepers did a messy job with writing up totals as you can see below. You are hired to clean up the mess using *R*.

```{r}
#| label: "zoo"
#| echo: true
#| message: false
#| warning: false

zoo <- c("bear x2", "Ostric7", "platypus x60", "x7 Eliphant", "x16 conDOR")

```

Use the functions in the `stringr` to clean up the string, taking out typos, etc. Generate an *R* dataframe with the following variables: *animal* (character), *number* (numeric). 


```{r}
#| label: "text_clean_exercise"
#| echo: true
#| message: false
#| warning: false

zoo <- c("bear x2", "Ostric7", "platypus x60", "x7 Eliphant", "x16 conDOR")

zoo <- str_to_lower(zoo)
zoo <- str_replace(zoo, "x", "")
zoo[2] <- str_replace(zoo[2], "7", "h 7")
zoo[4] <- str_replace(zoo[4], "eliphant", "elephant")
animal <- str_extract(zoo, "[a-z]+")
str(animal)
number <- str_extract(zoo, "\\d+")
str(number)

data <- data.frame(animal = as.character(animal), 
                   number = as.numeric(number), 
                   stringsAsFactors = FALSE)

print(data)
str(data)

```


Plot this data using `ggplot2`, call the resulting plot `zoo_plot`, and save it in a file called `zoo_plot.png` in the current working directory. 


```{r, out.width='\\textwidth'}

library(ggplot2)

zoo_plot <- ggplot(data, aes(x = animal, y = number)) +
  geom_bar(stat = "identity") +
  theme_minimal()

print(zoo_plot)

ggsave("zoo_plot.png")

```




